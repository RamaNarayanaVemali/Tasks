{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d45163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting review analysis...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>ðŸ“Š Review Analysis</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ba498890de49c08238765ed838504a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading NLTK Resources:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking punkt resource...\n",
      "âœ“ punkt already downloaded\n",
      "Checking stopwords resource...\n",
      "âœ“ stopwords already downloaded\n",
      "Checking wordnet resource...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"color: orange;\">Downloading missing resource: wordnet</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Successfully downloaded wordnet\n",
      "Checking averaged_perceptron_tagger resource...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"color: orange;\">Downloading missing resource: averaged_perceptron_tagger</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Successfully downloaded averaged_perceptron_tagger\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda73033343745d992e09b0c24fd1c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Reviews:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Processed Reviews:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Review 1:</strong> product quality amazing love</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Review 2:</strong> absolutely terrible experience service bad</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Review 3:</strong> great product fast delivery highly recommended</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Review 4:</strong> product okay expected better quality</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>Review 5:</strong> worst experience ever never buying</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Most Common Words:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>product: 3</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>quality: 2</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>experience: 2</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>amazing: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>love: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>absolutely: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>terrible: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>service: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>bad: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>great: 1</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import string\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set up logging for Jupyter Notebook with custom formatting\n",
    "def setup_notebook_logging():\n",
    "    \"\"\"Configure logging to display nicely in Jupyter Notebook\"\"\"\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                       format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                       datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Create a custom handler for Jupyter Notebook\n",
    "    class NotebookLoggingHandler(logging.Handler):\n",
    "        def emit(self, record):\n",
    "            if record.levelno >= logging.WARNING:\n",
    "                color = 'red' if record.levelno >= logging.ERROR else 'orange'\n",
    "                display(HTML(f'<div style=\"color: {color};\">{self.format(record)}</div>'))\n",
    "            else:\n",
    "                print(self.format(record))\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = []\n",
    "    logger.addHandler(NotebookLoggingHandler())\n",
    "    return logger\n",
    "\n",
    "def download_nltk_resources():\n",
    "    \"\"\"\n",
    "    Download required NLTK resources with progress tracking and error handling\n",
    "    \"\"\"\n",
    "    resources = [\n",
    "        ('punkt', 'tokenizers'),\n",
    "        ('stopwords', 'corpora'),\n",
    "        ('wordnet', 'corpora'),\n",
    "        ('averaged_perceptron_tagger', 'taggers')\n",
    "    ]\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    for resource, resource_type in tqdm(resources, desc=\"Downloading NLTK Resources\"):\n",
    "        try:\n",
    "            logger.info(f\"Checking {resource} resource...\")\n",
    "            nltk.data.find(f'{resource_type}/{resource}')\n",
    "            logger.info(f\"âœ“ {resource} already downloaded\")\n",
    "        except LookupError:\n",
    "            try:\n",
    "                logger.warning(f\"Downloading missing resource: {resource}\")\n",
    "                nltk.download(resource, quiet=True)\n",
    "                logger.info(f\"âœ“ Successfully downloaded {resource}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to download {resource}: {str(e)}\")\n",
    "                raise RuntimeError(f\"Critical resource {resource} could not be downloaded\") from e\n",
    "\n",
    "def analyze_reviews(reviews):\n",
    "    \"\"\"\n",
    "    Analyze customer reviews with comprehensive error handling and progress tracking\n",
    "    \n",
    "    Args:\n",
    "        reviews (list): List of review strings\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (processed_reviews, word_frequency)\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    try:\n",
    "        # Initialize NLTK resources\n",
    "        download_nltk_resources()\n",
    "        \n",
    "        # Initialize tools\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        processed_reviews = []\n",
    "        all_words = []\n",
    "        \n",
    "        # Process each review with progress bar\n",
    "        for review in tqdm(reviews, desc=\"Processing Reviews\"):\n",
    "            try:\n",
    "                # Convert to lowercase\n",
    "                review = review.lower()\n",
    "                logger.debug(f\"Processing review: {review[:50]}...\")\n",
    "                \n",
    "                # Tokenization\n",
    "                tokens = word_tokenize(review)\n",
    "                \n",
    "                # Remove punctuation and numbers\n",
    "                tokens = [token for token in tokens if token not in string.punctuation and not token.isnumeric()]\n",
    "                \n",
    "                # Remove stopwords\n",
    "                tokens = [token for token in tokens if token not in stop_words]\n",
    "                \n",
    "                # Lemmatization\n",
    "                lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "                \n",
    "                processed_reviews.append(lemmatized)\n",
    "                all_words.extend(lemmatized)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing review: {str(e)}\")\n",
    "                logger.error(f\"Problematic review: {review}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate word frequency\n",
    "        word_freq = Counter(all_words)\n",
    "        \n",
    "        return processed_reviews, word_freq\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Critical error in analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Usage example for Jupyter Notebook\n",
    "def run_analysis(reviews):\n",
    "    \"\"\"\n",
    "    Run the analysis with proper setup for Jupyter Notebook\n",
    "    \"\"\"\n",
    "    # Setup logging\n",
    "    logger = setup_notebook_logging()\n",
    "    logger.info(\"Starting review analysis...\")\n",
    "    \n",
    "    try:\n",
    "        # Show setup message\n",
    "        display(HTML(\"<h3>ðŸ“Š Review Analysis</h3>\"))\n",
    "        \n",
    "        # Run analysis\n",
    "        processed_reviews, word_frequency = analyze_reviews(reviews)\n",
    "        \n",
    "        # Display results\n",
    "        display(HTML(\"<h4>Processed Reviews:</h4>\"))\n",
    "        for i, review in enumerate(processed_reviews, 1):\n",
    "            display(HTML(f\"<p><strong>Review {i}:</strong> {' '.join(review)}</p>\"))\n",
    "        \n",
    "        display(HTML(\"<h4>Most Common Words:</h4>\"))\n",
    "        for word, count in word_frequency.most_common(10):\n",
    "            display(HTML(f\"<p>{word}: {count}</p>\"))\n",
    "            \n",
    "        logger.info(\"Analysis completed successfully!\")\n",
    "        return processed_reviews, word_frequency\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Sample reviews\n",
    "reviews = [\n",
    "    \"The product quality is amazing! I love it.\",\n",
    "    \"Absolutely terrible experience. The service was bad.\",\n",
    "    \"Great product and fast delivery. Highly recommended!\",\n",
    "    \"The product was okay, but I expected better quality.\",\n",
    "    \"Worst experience ever. Never buying again.\"\n",
    "]\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    processed_reviews, word_frequency = run_analysis(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225d269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
